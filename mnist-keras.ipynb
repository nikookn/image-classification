{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE MNIST DATABASE of handwritten digits\n",
    "\n",
    "The MNIST database of handwritten digits, available from [here](http://yann.lecun.com/exdb/mnist/), has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
    "\n",
    "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n",
    "\n",
    "Four files are available on this site:\n",
    "```\n",
    "train-images-idx3-ubyte.gz:  training set images\n",
    "train-labels-idx1-ubyte.gz:  training set labels\n",
    "t10k-images-idx3-ubyte.gz:   test set images\n",
    "t10k-labels-idx1-ubyte.gz:   test set labels\n",
    "```\n",
    "These files are not in any standard image format. You have to write your own (very simple) program to read them. However, [keras](https://www.tensorflow.org/api_docs/python/tf/keras) has helper function, [``keras.datasets.mnist.load_data``](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data), that allows you to load this dataset easily. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and prepare the MNIST dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``x_train`` and ``x_test`` are ``uint8`` arrays of grayscale image data with shapes ``(num_samples, 28, 28)``. ``y_train`` and ``y_test`` are ``uint8`` arrays of digit labels (integers in range 0-9) with shapes ``(num_samples,)``.\n",
    "\n",
    "Let's normalize the image samples from integers (in range 0-255) to floating-point numbers (in range 0.0-1.0):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build the ``Sequential`` model by stacking layers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each example the model returns a vector of \"[logits](https://developers.google.com/machine-learning/glossary#logits)\" scores, one for each class.\n",
    "\n",
    "Now, we choose an optimizer and loss function for training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [``losses.SparseCategoricalCrossentropy``](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) loss takes a vector of logits and a ``True`` index and returns a scalar loss for each example. This loss is equal to the negative log probability of the true class: It is zero if the model is sure of the correct class.\n",
    "\n",
    "Now, let's train our model. The ``fit`` method adjusts the model parameters to minimize the loss:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 738us/step - loss: 0.2974 - accuracy: 0.9141\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 734us/step - loss: 0.1426 - accuracy: 0.9576\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 825us/step - loss: 0.1049 - accuracy: 0.9690\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.0874 - accuracy: 0.9732\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 934us/step - loss: 0.0723 - accuracy: 0.9774\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 866us/step - loss: 0.0651 - accuracy: 0.9794\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 639us/step - loss: 0.0568 - accuracy: 0.9821\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0521 - accuracy: 0.9831\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 1s 668us/step - loss: 0.0470 - accuracy: 0.9845\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 1s 759us/step - loss: 0.0430 - accuracy: 0.9853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a3b4d00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that our model is trained, it's time to evaluate its performance on an unseen dataset. The ``evaluate`` method checks the models performance on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0696 - accuracy: 0.9801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06963185966014862, 0.9800999760627747]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the image classifier is now trained to ~98% accuracy on this dataset.\n",
    "\n",
    "If you want your model to return a probability instead of logits, you can wrap the trained model, and attach the softmax to it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = keras.Sequential([\n",
    "  model,\n",
    "  keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:1]).numpy().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "\n",
    "Now, let's change our model to take advantage of convolutional neural networks. But, we need to add a channels dimension before feeding the data to [``keras.layers.Conv2D``](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
    "x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build the ``Sequential`` model by stacking layers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               2769024   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,770,634\n",
      "Trainable params: 2,770,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu', input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we choose an optimizer and loss function for training for the new model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.compile(optimizer='adam', \n",
    "                   loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train our new model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 25s 14ms/step - loss: 0.1417 - accuracy: 0.9562\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0433 - accuracy: 0.9858\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0228 - accuracy: 0.9927\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0135 - accuracy: 0.9955\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0090 - accuracy: 0.9970\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0075 - accuracy: 0.9973\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 27s 15ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0029 - accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.0037 - accuracy: 0.9989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14ab350d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that our model is trained, let's evaluate its performance on the test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0782 - accuracy: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07824727147817612, 0.9860000014305115]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the image classifier is now trained to ~98% accuracy on this dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
